{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "assignment4_Smirnova.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J26xzhfHmwag",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4: Named entity recognition\n",
        "\n",
        "Create a model for Named Entity Recognition for dataset CoNLL 2002.  \n",
        "Your quality metric = f1_macro\n",
        "\n",
        "In your solution you should use: RandomForest, Gradient Boosting (xgboost, lightgbm, catboost)   \n",
        "Tutorials:  \n",
        "1. https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide\n",
        "1. https://github.com/catboost/tutorials \n",
        "\n",
        "More baselines you beat - better your score\n",
        " \n",
        "baseline 1 [3 points]: 0.0604      random labels  \n",
        "baseline 2 [5 points]: 0.3966      PoS features + logistic regression  \n",
        "baseline 3 [8 points]: 0.8122      word2vec cbow embedding + baseline 2 + svm    \n",
        "\n",
        "[1 point] using feature engineering (creating features not presented in the baselines)\n",
        "\n",
        "! Your results must be reproducible. You should explicitly set all seeds random_states in yout model.  \n",
        "! Remember to use proper training pipeline.  \n",
        "\n",
        "bonus, think about:  \n",
        "1. [1 point] Why did we select f1 score with macro averaging as our classification quality measure? What other metrics are suitable?   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHlPEYnlmynP",
        "colab_type": "code",
        "outputId": "0609b750-8540-48f8-8583-de00695a7849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "!wget 'https://www.dropbox.com/s/0nzylhci63vsfcv/data.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-02 20:58:34--  https://www.dropbox.com/s/0nzylhci63vsfcv/data.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/0nzylhci63vsfcv/data.zip [following]\n",
            "--2019-12-02 20:58:35--  https://www.dropbox.com/s/raw/0nzylhci63vsfcv/data.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc95f2c120912dcd6abd92cd94b4.dl.dropboxusercontent.com/cd/0/inline/Atdd4GAzip5eawM7ijzQfn0ZblobI8i-uqdbP7FgctuhxWzw-OriE1-sClHF1jYNefCD3AEf7g8T2XvVqgy13qIHjZORaaUs4-rx6AZICXzgWHgCmo2VUKwKhQY2lCs8RgY/file# [following]\n",
            "--2019-12-02 20:58:35--  https://uc95f2c120912dcd6abd92cd94b4.dl.dropboxusercontent.com/cd/0/inline/Atdd4GAzip5eawM7ijzQfn0ZblobI8i-uqdbP7FgctuhxWzw-OriE1-sClHF1jYNefCD3AEf7g8T2XvVqgy13qIHjZORaaUs4-rx6AZICXzgWHgCmo2VUKwKhQY2lCs8RgY/file\n",
            "Resolving uc95f2c120912dcd6abd92cd94b4.dl.dropboxusercontent.com (uc95f2c120912dcd6abd92cd94b4.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
            "Connecting to uc95f2c120912dcd6abd92cd94b4.dl.dropboxusercontent.com (uc95f2c120912dcd6abd92cd94b4.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AtfnfTPD6hWWCgagNj_DfedM9qQ-FraS5dz7VLyo7MC8SLWhQFB1NP5KI3cr_ZTdqLmp1u84Mk5Amim5G0gDbZIIt-T-rdOn0SPGh2zvu-c5_IbZdZG086kA-eFnlKGmkAys3N3T14v8FMVChEccsn_5HNcqhhDs2vMeMH9bGD9lr5MyFPb7Qf7eUxQ6w9iiZ9RwOau75uE-Y2F6g3HsOjXj4RZDyvBMsHOTeho2aIwBkA5gvbKQqZ9YVe9quwlOSF-RVh7O795w6wWu0vPptxnw9qOqTVyZtYx-iTZrHa5QGMbWg6r9eZ32j_JlInFRbOE8qkPTgLs7P6rLwL9CYtNe0tDIbmkRdhQg2729bauuMg/file [following]\n",
            "--2019-12-02 20:58:36--  https://uc95f2c120912dcd6abd92cd94b4.dl.dropboxusercontent.com/cd/0/inline2/AtfnfTPD6hWWCgagNj_DfedM9qQ-FraS5dz7VLyo7MC8SLWhQFB1NP5KI3cr_ZTdqLmp1u84Mk5Amim5G0gDbZIIt-T-rdOn0SPGh2zvu-c5_IbZdZG086kA-eFnlKGmkAys3N3T14v8FMVChEccsn_5HNcqhhDs2vMeMH9bGD9lr5MyFPb7Qf7eUxQ6w9iiZ9RwOau75uE-Y2F6g3HsOjXj4RZDyvBMsHOTeho2aIwBkA5gvbKQqZ9YVe9quwlOSF-RVh7O795w6wWu0vPptxnw9qOqTVyZtYx-iTZrHa5QGMbWg6r9eZ32j_JlInFRbOE8qkPTgLs7P6rLwL9CYtNe0tDIbmkRdhQg2729bauuMg/file\n",
            "Reusing existing connection to uc95f2c120912dcd6abd92cd94b4.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1064698 (1.0M) [application/zip]\n",
            "Saving to: ‘data.zip.3’\n",
            "\n",
            "data.zip.3          100%[===================>]   1.01M  3.63MB/s    in 0.3s    \n",
            "\n",
            "2019-12-02 20:58:36 (3.63 MB/s) - ‘data.zip.3’ saved [1064698/1064698]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXj3XXd6wqv2",
        "colab_type": "code",
        "outputId": "d5e5ab8c-8439-4b5d-cc92-07861bff4cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!unzip 'data.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace data/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/data/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace data/ner_short.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/data/._ner_short.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/._data? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tM6Z2rqmwak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn import model_selection\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "SEED=1337"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFErMs5lmwao",
        "colab_type": "code",
        "outputId": "41ae5bc7-1912-48f6-c922-e479095e4fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "df = pd.read_csv('data/ner_short.csv', index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NNP</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  next-next-pos next-next-word next-pos  ... sentence_idx           word tag\n",
              "0           NNS  demonstrators       IN  ...          1.0      Thousands   O\n",
              "1           VBP           have      NNS  ...          1.0             of   O\n",
              "2           VBN        marched      VBP  ...          1.0  demonstrators   O\n",
              "3            IN        through      VBN  ...          1.0           have   O\n",
              "4           NNP         London       IN  ...          1.0        marched   O\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNUAsUlAmwav",
        "colab_type": "code",
        "outputId": "9885e14c-f4c9-4c6f-b0e6-b831667ca504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of sentences\n",
        "df.sentence_idx.max()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d5fgafqmwaz",
        "colab_type": "code",
        "outputId": "aa47cfb3-2a49-4b04-b4e6-10980b149b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# class distribution\n",
        "df.tag.value_counts(normalize=True )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        0.852828\n",
              "B-geo    0.027604\n",
              "B-gpe    0.020935\n",
              "B-org    0.020247\n",
              "I-per    0.017795\n",
              "B-tim    0.016927\n",
              "B-per    0.015312\n",
              "I-org    0.013937\n",
              "I-geo    0.005383\n",
              "I-tim    0.004247\n",
              "B-art    0.001376\n",
              "I-gpe    0.000837\n",
              "I-art    0.000748\n",
              "B-eve    0.000628\n",
              "I-eve    0.000508\n",
              "B-nat    0.000449\n",
              "I-nat    0.000239\n",
              "Name: tag, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVBO8kf5mwa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentence length\n",
        "tdf = df.set_index('sentence_idx')\n",
        "tdf['length'] = df.groupby('sentence_idx').tag.count()\n",
        "df = tdf.reset_index(drop=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNlborKhmwa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode categorial variables\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['pos'] = le.fit_transform(df.pos)\n",
        "df['next-pos'] = le.fit_transform(df['next-pos'])\n",
        "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
        "df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
        "df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFIevmj2mwbB",
        "colab_type": "code",
        "outputId": "2a9ef2be-af8f-4eb1-a72b-a3813b130289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>London</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_idx  next-next-pos next-next-word  ...           word tag  length\n",
              "0           1.0             18  demonstrators  ...      Thousands   O      48\n",
              "1           1.0             33           have  ...             of   O      48\n",
              "2           1.0             32        marched  ...  demonstrators   O      48\n",
              "3           1.0              9        through  ...           have   O      48\n",
              "4           1.0             16         London  ...        marched   O      48\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwqjdBvAmwbD",
        "colab_type": "code",
        "outputId": "88c0f854-fdc8-4f07-d54b-b727ca572dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# splitting\n",
        "y = LabelEncoder().fit_transform(df.tag)\n",
        "\n",
        "df_train, df_test, y_train, y_test = model_selection.train_test_split(df, y, stratify=y, \n",
        "                                                                      test_size=0.25, random_state=SEED, shuffle=True)\n",
        "print('train', df_train.shape[0])\n",
        "print('test', df_test.shape[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 50155\n",
            "test 16719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uFChIBkmwbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some wrappers to work with word2vec\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from collections import defaultdict\n",
        "\n",
        "   \n",
        "class Word2VecWrapper(TransformerMixin):\n",
        "    def __init__(self, window=5,negative=5, size=300, iter=100, is_cbow=False, random_state=SEED):\n",
        "        self.window_ = window\n",
        "        self.negative_ = negative\n",
        "        self.size_ = size\n",
        "        self.iter_ = iter\n",
        "        self.is_cbow_ = is_cbow\n",
        "        self.w2v = None\n",
        "        self.random_state = random_state\n",
        "        \n",
        "    def get_size(self):\n",
        "        return self.size_\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        X: list of strings\n",
        "        \"\"\"\n",
        "        sentences_list = [x.split() for x in X]\n",
        "        self.w2v = Word2Vec(sentences_list, \n",
        "                            window=self.window_,\n",
        "                            negative=self.negative_, \n",
        "                            size=self.size_, \n",
        "                            iter=self.iter_,\n",
        "                            sg=not self.is_cbow_, seed=self.random_state)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def has(self, word):\n",
        "        return word in self.w2v\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        X: a list of words\n",
        "        \"\"\"\n",
        "        if self.w2v is None:\n",
        "            raise Exception('model not fitted')\n",
        "        return np.array([self.w2v[w] if w in self.w2v else np.zeros(self.size_) for w in X ])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcXvLTHQmwbJ",
        "colab_type": "code",
        "outputId": "7fc4fa39-fa75-4b31-c73b-e73dca034a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "# here we exploit that word2vec is an unsupervised learning algorithm\n",
        "# so we can train it on the whole dataset (subject to discussion)\n",
        "\n",
        "sentences_list = [x.strip() for x in ' '.join(df.word).split('.')]\n",
        "\n",
        "w2v_cbow = Word2VecWrapper(window=5, negative=5, size=300, iter=300, is_cbow=True, random_state=SEED)\n",
        "w2v_cbow.fit(sentences_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 48 s, sys: 451 ms, total: 48.5 s\n",
            "Wall time: 27.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAjPs42FmwbP",
        "colab_type": "code",
        "outputId": "17afdb08-9f95-4e64-f85b-fae055f2b173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "%%time\n",
        "# baseline 1 \n",
        "# random labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('est', DummyClassifier(random_state=SEED)),\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.05887736725599869\n",
            "test 0.060439542712750365\n",
            "CPU times: user 131 ms, sys: 13 ms, total: 144 ms\n",
            "Wall time: 160 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uef-pDLimwbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# baseline 2 \n",
        "# pos features + one hot encoding + logistic regression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('est', LogisticRegressionCV(Cs=5, cv=5, n_jobs=-1, scoring='f1_macro', \n",
        "                             penalty='l2', solver='newton-cg', multi_class='multinomial', random_state=SEED)),\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6jCiWSjmwbV",
        "colab_type": "code",
        "outputId": "0eca5e7a-6a2a-4542-85d3-c44e709d0981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "%%time\n",
        "# baseline 3\n",
        "# use word2vec cbow embedding + baseline 2 + svm\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.svm import LinearSVC\n",
        "import scipy.sparse as sp\n",
        "\n",
        "embeding = w2v_cbow\n",
        "encoder_pos = OneHotEncoder()\n",
        "X_train = sp.hstack([\n",
        "    embeding.transform(df_train.word),\n",
        "    embeding.transform(df_train['next-word']),\n",
        "    embeding.transform(df_train['next-next-word']),\n",
        "    embeding.transform(df_train['prev-word']),\n",
        "    embeding.transform(df_train['prev-prev-word']),\n",
        "    encoder_pos.fit_transform(df_train[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
        "])\n",
        "X_test = sp.hstack([\n",
        "    embeding.transform(df_test.word),\n",
        "    embeding.transform(df_test['next-word']),\n",
        "    embeding.transform(df_test['next-next-word']),\n",
        "    embeding.transform(df_test['prev-word']),\n",
        "    embeding.transform(df_test['prev-prev-word']),\n",
        "    encoder_pos.transform(df_test[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
        "])\n",
        "\n",
        "model = model_selection.GridSearchCV(LinearSVC(penalty='l2', multi_class='ovr', random_state=SEED), \n",
        "                                    {'C': np.logspace(-4, 0, 5)}, \n",
        "                                    cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 14.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train 0.9556044410366434\n",
            "test 0.7969558492427843\n",
            "CPU times: user 2min 53s, sys: 1.39 s, total: 2min 54s\n",
            "Wall time: 17min 47s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YP8KkUN2IvN",
        "colab_type": "text"
      },
      "source": [
        "# Beating 1st Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kypUz8l-3qrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "import scipy as sp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMtXAEI28Ab6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('xgb', XGBClassifier(random_state=SEED))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quf_WzF-mwbe",
        "colab_type": "code",
        "outputId": "0236aa83-45e5-4379-c216-b348ff6c6d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.39326124218078107\n",
            "test 0.3353187957066505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMs_oAPaO0AO",
        "colab_type": "text"
      },
      "source": [
        "#Beating 2nd Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0ifsgLsP2o7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "n_est = [5, 10, 20, 30, 40, 50, 75, 100, 250, 500]\n",
        "f1_scores = []\n",
        "for n in n_est:\n",
        "  model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('lgbm', RandomForestClassifier(n_estimators=n, random_state=SEED))\n",
        "  ])\n",
        "  model.fit(df_train[columns], y_train)\n",
        "  f1 = metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro')\n",
        "  f1_scores.append(f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJpNZlauQFCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "7161f862-9f22-4f9e-99da-e9dde2ad0834"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(n_est[:-2], f1_scores[:-2])\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+cjgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh8cA2GiRuIT",
        "colab_type": "text"
      },
      "source": [
        "### Best Parameter: 30 estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9OxfgqHR07G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "652152b0-7238-4910-ef14-155fe5ee2a3c"
      },
      "source": [
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('rfc', RandomForestClassifier(n_estimators=30, random_state=SEED)),\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.7454657848505839\n",
            "test 0.6055799325457629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W_4kfH4T4yJ",
        "colab_type": "text"
      },
      "source": [
        "# Question\n",
        "* F1 was chosen because it combines two main metrics - precision and recall, which shows us both the number of correctly predicted positive labels divided by real right labels, and the number of correctly predicted positive labels divided by all predicted positive labels.\n",
        "* `weighted` is chosen because it demonstrates the \"grouping\" of the predicted labels. We could use other `average` parameter, e.g. `macro`, which will not show grouping."
      ]
    }
  ]
}